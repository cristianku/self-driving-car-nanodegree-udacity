{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "n_hidden_layer = 256 # layer number of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "x_flat = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.matmul(layer_1, weights['out']) + biases['out']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define loss and optimizer\n",
    "prediction = tf.nn.softmax(logits)\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "cost = tf.reduce_mean(softmax)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_size =128\n",
      "Epoch: 0001 cost= 48.657333374\n",
      "Epoch: 0002 cost= 21.438283920\n",
      "Optimization Finished!\n",
      "Accuracy: 0.540039\n",
      "correct_prediction: [ True  True  True ...,  True False False]\n",
      "Weights:\n",
      "{'hidden_layer': array([[ 0.52260715,  0.36194354,  1.15915215, ...,  1.48484218,\n",
      "        -0.83883947, -1.53478658],\n",
      "       [-0.82478756, -0.11059668, -0.9444325 , ..., -0.22422895,\n",
      "         0.70220792, -0.72232765],\n",
      "       [ 0.42899022, -0.28473249,  1.92995644, ..., -0.3884367 ,\n",
      "        -0.90176755,  1.60891128],\n",
      "       ..., \n",
      "       [ 0.92145395,  1.79014432, -0.14061682, ..., -0.45599887,\n",
      "        -1.39776433,  0.99480766],\n",
      "       [-1.12842727,  1.28835273,  1.57863283, ..., -0.53346354,\n",
      "        -0.06810507, -0.16403013],\n",
      "       [-0.28524476,  0.62323403, -0.70684636, ..., -2.09331012,\n",
      "        -0.42336324, -0.25602502]], dtype=float32), 'out': array([[-3.35626507, -0.43102735, -0.26562142, ..., -1.76731455,\n",
      "        -0.67417502,  2.65314841],\n",
      "       [ 0.44706994, -0.40910265,  0.60696334, ..., -0.29546452,\n",
      "         1.13085079,  0.74329424],\n",
      "       [ 2.78220391,  1.70455766, -0.42031693, ...,  0.12919538,\n",
      "         0.17361842,  1.13534677],\n",
      "       ..., \n",
      "       [ 3.01835608, -0.24813755,  1.77735579, ..., -0.40086693,\n",
      "        -0.95542532, -1.03908288],\n",
      "       [-1.19979858,  0.35671186, -2.55411053, ..., -0.57806802,\n",
      "        -0.21468128, -0.07348476],\n",
      "       [-0.89538765, -1.85850918, -0.44678339, ...,  0.01147484,\n",
      "         1.21563649, -1.46686983]], dtype=float32)}\n",
      "Bias:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-6a4c8219dcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bias:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bias' is not defined"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "    \n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    print (' batch_size =' + str(batch_size))\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        print \n",
    "        #for i in range(total_batch):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Display logs per epoch step\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(c))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    # Decrease test_size if you don't have enough memory\n",
    "    test_size = 1024\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images[:test_size], y: mnist.test.labels[:test_size]}))\n",
    "    print(\"correct_prediction:\", correct_prediction.eval({x: mnist.test.images[:test_size], y: mnist.test.labels[:test_size]}))\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('biases:')\n",
    "    print(sess.run(biases))\n",
    "    \n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight:\n",
      "{'hidden_layer': array([[-0.98892301, -1.57155097, -0.14187942, ..., -1.32107496,\n",
      "        -0.01772454, -0.24196029],\n",
      "       [ 1.53327477,  1.54927087, -0.29659238, ..., -0.00639775,\n",
      "        -0.05408255,  0.11464947],\n",
      "       [ 0.18619156, -0.32015783, -1.2448436 , ..., -0.27074164,\n",
      "         0.82799983,  0.71401256],\n",
      "       ..., \n",
      "       [ 0.53019553,  1.67417979,  2.15782499, ..., -0.13993046,\n",
      "         0.03908987, -0.96617848],\n",
      "       [-1.46454298, -1.66629052,  0.6271733 , ..., -1.03570509,\n",
      "        -1.14028347, -1.22107518],\n",
      "       [-0.94389021, -0.2587868 ,  0.09722459, ..., -1.06019402,\n",
      "         0.56700164,  1.47219467]], dtype=float32), 'out': array([[-0.91349465, -0.55251551,  0.13756041, ..., -0.27841979,\n",
      "        -0.68965828,  0.03508285],\n",
      "       [ 0.22733082, -1.06088209,  1.20574021, ..., -1.39120674,\n",
      "        -0.31606284, -0.5210287 ],\n",
      "       [-0.51164848,  0.05055892,  0.13681965, ..., -1.43161213,\n",
      "         0.06150173,  0.78549725],\n",
      "       ..., \n",
      "       [-0.66334915,  0.70059842, -2.19106555, ...,  0.0774924 ,\n",
      "         1.06040597, -0.31326106],\n",
      "       [ 0.02834775, -0.50222731,  0.36105749, ..., -1.18875027,\n",
      "         1.33255148, -0.38257286],\n",
      "       [-0.89331019, -0.40392581, -0.24278706, ...,  0.71531886,\n",
      "        -0.08170752,  0.22039443]], dtype=float32)}\n",
      "biases:\n",
      "{'hidden_layer': array([ -1.52887177e+00,  -1.03121686e+00,  -1.03786778e+00,\n",
      "         1.51106012e+00,   2.22967967e-01,   2.88533616e+00,\n",
      "        -5.57908602e-02,   2.06047520e-01,  -9.91469383e-01,\n",
      "         1.55093372e+00,  -1.17293823e+00,  -6.57155752e-01,\n",
      "         1.96728766e-01,  -1.36434436e-01,   1.54104978e-01,\n",
      "        -7.76463926e-01,  -5.54321110e-01,   1.28665113e+00,\n",
      "         5.47005534e-01,  -7.31815517e-01,  -1.68346095e+00,\n",
      "        -4.26917911e-01,   4.12413418e-01,  -1.12990844e+00,\n",
      "         3.57598215e-01,  -1.03470765e-01,  -1.05615020e-01,\n",
      "         8.39503229e-01,   1.02758300e+00,   1.23005807e+00,\n",
      "         1.45329237e+00,   1.08985388e+00,   1.25106478e+00,\n",
      "         1.19525898e+00,   2.94877030e-02,  -2.26634121e+00,\n",
      "        -7.14103639e-01,   4.15862352e-01,  -1.18938088e+00,\n",
      "         3.58248234e-01,   6.30507946e-01,   1.34476137e+00,\n",
      "         3.29948008e-01,  -6.04243577e-01,  -2.88730145e-01,\n",
      "        -8.42806876e-01,  -2.66740203e-01,  -8.16400170e-01,\n",
      "        -1.03928638e+00,  -1.03963697e+00,  -2.64065832e-01,\n",
      "         1.25599253e+00,   5.63417554e-01,   3.33627194e-01,\n",
      "         1.51867867e+00,  -9.81169879e-01,   2.08788529e-01,\n",
      "        -1.56798518e+00,  -6.42374516e-01,  -7.37799346e-01,\n",
      "        -1.72698689e+00,   2.28826809e+00,  -1.48695803e+00,\n",
      "        -1.49931848e+00,   6.38790727e-01,   1.94975066e+00,\n",
      "         7.76222587e-01,  -9.21817362e-01,   8.08036745e-01,\n",
      "        -1.01168954e+00,  -2.59011507e-01,  -1.12274969e+00,\n",
      "         3.11094260e+00,   3.41725767e-01,  -4.16392237e-01,\n",
      "        -2.63745093e+00,   2.71793294e+00,  -7.39857078e-01,\n",
      "         4.44513410e-01,  -2.84257978e-01,   8.36376566e-03,\n",
      "        -1.85916686e+00,  -9.02487278e-01,   4.50659364e-01,\n",
      "         4.55675393e-01,  -6.96849644e-01,   5.73306859e-01,\n",
      "         1.61922264e+00,  -1.24943209e+00,  -5.87354898e-01,\n",
      "        -1.00155365e+00,   1.14699334e-01,  -5.35756590e-05,\n",
      "         8.60089183e-01,  -2.76260644e-01,  -1.09546220e+00,\n",
      "         9.91583228e-01,   7.61102915e-01,  -6.03648350e-02,\n",
      "        -4.15316552e-01,   2.78252214e-01,  -9.50062752e-01,\n",
      "         9.66532230e-01,  -6.19446993e-01,  -9.09852564e-01,\n",
      "         2.10020065e-01,   4.38302606e-01,   1.08587593e-01,\n",
      "        -2.22248305e-03,  -2.16735572e-01,  -4.99209553e-01,\n",
      "        -6.30768001e-01,  -1.29016265e-01,   1.15322843e-01,\n",
      "        -5.54088242e-02,  -8.29237163e-01,   1.04810989e+00,\n",
      "         6.68038845e-01,  -8.45224679e-01,  -2.55154908e-01,\n",
      "        -1.22652531e+00,   5.23343384e-01,  -6.77311718e-01,\n",
      "         7.59287357e-01,   2.69649416e-01,   6.96262956e-01,\n",
      "        -3.53270859e-01,  -1.06748927e+00,  -1.58064532e+00,\n",
      "         6.85944796e-01,   1.27363241e+00,   2.98649967e-01,\n",
      "         3.36194426e-01,  -5.88375963e-02,  -3.05417478e-01,\n",
      "        -7.53621340e-01,   7.39487052e-01,  -6.90603971e-01,\n",
      "         2.51305670e-01,   5.31455576e-02,  -6.49967343e-02,\n",
      "         2.42233779e-02,   1.26980603e-01,  -2.00987548e-01,\n",
      "         8.80781949e-01,  -7.70401582e-02,   1.22891940e-01,\n",
      "         5.61212957e-01,  -2.80318677e-01,  -8.69810641e-01,\n",
      "         5.64714074e-01,  -1.24596439e-01,  -7.30994880e-01,\n",
      "         2.12975144e+00,   3.20539512e-02,  -1.93255508e+00,\n",
      "        -1.08591509e+00,  -6.60121202e-01,  -4.29008543e-01,\n",
      "         1.50624645e+00,  -5.80637753e-01,   5.40060163e-01,\n",
      "         4.03683841e-01,   2.64414158e-02,   6.10451996e-02,\n",
      "        -8.71091843e-01,   4.21261936e-01,   5.90817593e-02,\n",
      "        -5.82162678e-01,   1.30754769e+00,  -2.57638276e-01,\n",
      "        -1.11686993e+00,   9.90728885e-02,  -2.38128617e-01,\n",
      "         1.55166924e+00,   2.13617325e+00,   7.85465658e-01,\n",
      "         1.14910173e+00,  -1.11071801e+00,   3.00722659e-01,\n",
      "        -2.60187149e-01,  -5.23538589e-01,   5.66211700e-01,\n",
      "         5.19999683e-01,  -4.36025262e-01,   1.98940098e+00,\n",
      "        -3.82593781e-01,   1.13089573e+00,   5.19484341e-01,\n",
      "        -3.52171659e-01,  -4.61503536e-01,  -1.65584207e+00,\n",
      "         1.93687427e+00,  -6.37658000e-01,  -2.37766683e-01,\n",
      "        -4.58597720e-01,  -3.03841662e-02,  -8.62409890e-01,\n",
      "        -1.87233627e-01,  -8.66705596e-01,  -9.21611428e-01,\n",
      "        -1.83004630e+00,  -2.47167066e-01,  -5.28798819e-01,\n",
      "         7.69138455e-01,   1.14366829e+00,  -9.41387355e-01,\n",
      "         1.14530015e+00,   7.99877286e-01,   5.61172515e-02,\n",
      "         2.48431876e-01,   6.25052512e-01,  -9.43371475e-01,\n",
      "        -3.41781199e-01,  -1.13610721e+00,  -1.04309404e+00,\n",
      "         5.46288252e-01,  -2.31130589e-02,   1.96221083e-01,\n",
      "        -1.62275469e+00,   8.93988669e-01,   7.04516768e-01,\n",
      "        -9.39838290e-01,   2.28177428e-01,  -2.33105063e-01,\n",
      "         3.79061610e-01,  -1.05463886e+00,   1.09277415e+00,\n",
      "        -4.14781809e-01,  -1.21334648e+00,  -5.38265467e-01,\n",
      "         6.43913269e-01,   1.54913628e+00,  -2.09971404e+00,\n",
      "        -1.25950813e-01,  -3.23694497e-01,   3.11643928e-01,\n",
      "         1.60273895e-01,  -9.32938159e-01,  -2.17334151e-01,\n",
      "        -1.40926957e+00,  -9.76559758e-01,   1.14232481e+00,\n",
      "         2.10281551e-01,   1.20793009e+00,  -1.65970877e-01,\n",
      "         1.61316264e+00,   8.20583224e-01,  -1.57125175e+00,\n",
      "         2.01083153e-01,  -5.60966849e-01,  -2.27582261e-01,\n",
      "         3.38453203e-01,   2.02149451e-01,  -9.44361508e-01,\n",
      "        -9.43628788e-01], dtype=float32), 'out': array([-0.82055658, -1.07510829,  0.87611288,  0.61438048, -0.95498884,\n",
      "        0.33067358,  0.28070313, -1.24390268,  1.73003542,  0.30773845], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('biases:')\n",
    "    print(sess.run(biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
